{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "from utils.paths import URL_CONFIG_PATH, BOOKS_PATH, AUTHORS_PATH\n",
    "from utils.enums import URLS, SOUP\n",
    "from utils.regex import NUMBER_PATTERN, LITERAL_PATTERN\n",
    "\n",
    "from scraping.pages import scrape_books\n",
    "from scraping.session import get_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(URL_CONFIG_PATH) as url_config_file:\n",
    "    urls = json.load(url_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "def get_with_retry(session, url, retries=5):\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            html = session.get(url).text\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f'Error: {e}')\n",
    "            time.sleep(.5)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n",
      "Current step: 343\r"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store book and author data\n",
    "books_data_dict_list = []\n",
    "authors_data_dict_list = []\n",
    "\n",
    "# give visited_books\n",
    "if BOOKS_PATH.exists():\n",
    "    visited_books = set(pd.read_csv(BOOKS_PATH)['url'].unique())\n",
    "else:\n",
    "    visited_books = set()\n",
    "\n",
    "# give visited_authors\n",
    "if AUTHORS_PATH.exists():\n",
    "    visited_authors = set(pd.read_csv(AUTHORS_PATH)['author_url'].unique())\n",
    "else:\n",
    "    visited_authors = set()\n",
    "\n",
    "# Loop through pages to scrape book URLs\n",
    "try:\n",
    "    for step in range(1, 344):\n",
    "        books_urls = scrape_books(base_url=urls[URLS.BASE], page_url=urls[URLS.PAGE].format(step=step), session=session)\n",
    "        \n",
    "        # Loop through each book URL to scrape book details\n",
    "        for book_url in books_urls:\n",
    "            # book_html = session.get(book_url).text\n",
    "            book_html = get_with_retry(session, book_url)\n",
    "            soup_book = BeautifulSoup(book_html, SOUP.HTML_PARSER)\n",
    "            \n",
    "\n",
    "            # Extract author names and hrefs\n",
    "            authors_html = soup_book.find_all('a', class_='link-name d-inline-block')\n",
    "            authors_names = [author.text for author in authors_html]\n",
    "            authors_hrefs = [author['href'] for author in authors_html]\n",
    "\n",
    "            # Scrape author\n",
    "            author_href = authors_hrefs[0]\n",
    "            if author_href not in visited_authors:\n",
    "                author_html = get_with_retry(session, author_href)\n",
    "                author_soup = BeautifulSoup(author_html, SOUP.HTML_PARSER)\n",
    "                author_author_name = author_soup.find('div', class_='author-main__header-wrapper').text\n",
    "                author_average_rating = float(author_soup.find('div', class_='author-box').find('span', class_='rating__avarage').text.replace(',', '.'))\n",
    "                readers_div = author_soup.find_all('div', class_='author-box__readers-col')\n",
    "                if readers_div is not None:\n",
    "                    author_number_of_people_read = int(readers_div[0].find('span').text.replace(' ', ''))\n",
    "                    number_of_people_wants_to_read = int(readers_div[1].find('span').text.replace(' ', ''))\n",
    "                else:\n",
    "                    author_number_of_people_read = float('nan')\n",
    "                    number_of_people_wants_to_read = float('nan')\n",
    "                author_date_of_birth_span = author_soup.find('span', class_='author-info__born')\n",
    "                if author_date_of_birth_span is not None:\n",
    "                    author_date_of_birth =  author_date_of_birth_span.text.split()[-1]\n",
    "                else:\n",
    "                    author_date_of_birth = str(author_date_of_birth)\n",
    "                author_number_of_fans = int(author_soup.find('span', class_='author-box__number').text.replace(' ', ''))\n",
    "                author_number_of_books_written = int(author_soup.find('div', class_='author-info__count').text)\n",
    "                author_awards_html = author_soup.find('div', class_='author-info__count author-info__count--awards')\n",
    "                if author_awards_html is not None:\n",
    "                    author_number_of_awards = int(author_awards_html.text)\n",
    "                else:\n",
    "                    author_number_of_awards = 0\n",
    "                author_data_dict = {\n",
    "                    'author_name': author_author_name,\n",
    "                    'author_url': author_href,\n",
    "                    'author_average_rating': author_average_rating,\n",
    "                    'author_number_of_people_read': author_number_of_people_read,\n",
    "                    'author_number_of_people_wants_to_read': number_of_people_wants_to_read,\n",
    "                    'author_date_of_birth': author_date_of_birth,\n",
    "                    'author_number_of_fans': author_number_of_fans,\n",
    "                    'author_number_of_books_written': author_number_of_books_written,\n",
    "                    'author_number_of_awards': author_number_of_awards\n",
    "                }\n",
    "                authors_data_dict_list.append(author_data_dict)\n",
    "                visited_authors.add(author_href)\n",
    "            # Scrape author end\n",
    "\n",
    "            # scrape publisher\n",
    "            ...\n",
    "            # scrape publisher end\n",
    "            if book_url in visited_books:\n",
    "                continue\n",
    "            # Create a dictionary for authors\n",
    "            authors = {}\n",
    "            for index, (author_name, author_href) in enumerate(zip(authors_names, authors_hrefs)):\n",
    "                number = index if index > 0 else ''\n",
    "                authors[f'author{number}'] = author_name\n",
    "                authors[f'author_href{number}'] = author_href\n",
    "            \n",
    "            # Extract book details\n",
    "            pages_html = soup_book.find('span', class_='d-sm-inline-block book-pages book__pages pr-2 mr-2 pr-sm-3 mr-sm-3')\n",
    "            description_html = soup_book.find('div', class_='collapse-content')\n",
    "            description = description_html.text if description_html else ''\n",
    "            \n",
    "            # Extract user statistics\n",
    "            user_stats_html = soup_book.find('div', class_='d-flex flex-wrap justify-content-around px-3')\n",
    "            if user_stats_html is None:\n",
    "                number_of_discussions = 0\n",
    "                number_of_user_opinions = 0\n",
    "                number_of_user_ratings = 0\n",
    "            else:\n",
    "                user_stats = user_stats_html.text\n",
    "                user_stats = list(map(int, re.findall(NUMBER_PATTERN, user_stats)))\n",
    "            \n",
    "                if len(user_stats) == 2:\n",
    "                    number_of_user_opinions, number_of_user_ratings = user_stats\n",
    "                    number_of_discussions = 0\n",
    "                elif len(user_stats) == 3:\n",
    "                    number_of_user_opinions, number_of_user_ratings, number_of_discussions = user_stats\n",
    "            \n",
    "            # Extract additional book details\n",
    "            details_dict = dict(zip(\n",
    "                [element.text.strip().rstrip(':') for element in soup_book.find_all('dt')],\n",
    "                [element.text.strip() for element in soup_book.find_all('dd')]\n",
    "            ))\n",
    "            \n",
    "            # Extract on-the-shelf statistics\n",
    "            on_the_shelf_dict_raw = {\n",
    "                re.search(LITERAL_PATTERN, element.text).group().strip(): \"\".join(re.findall(NUMBER_PATTERN, element.text))\n",
    "                for element in soup_book.find_all('li', class_='list-group-item p-0')\n",
    "            }\n",
    "            on_the_shelf_dict = {\n",
    "                'number_of_people_read': on_the_shelf_dict_raw.get('Przeczytane', np.nan),\n",
    "                'number_of_people_has': on_the_shelf_dict_raw.get('Posiadam', np.nan),\n",
    "                'number_of_people_favorite': on_the_shelf_dict_raw.get('Ulubione', np.nan),\n",
    "                'number_of_people_wants_to_read': on_the_shelf_dict_raw.get('Chcę przeczytać', np.nan),\n",
    "                'number_of_people_wants_as_gift': on_the_shelf_dict_raw.get('Chcę w prezencie', np.nan),\n",
    "                'number_of_people_currently_read': on_the_shelf_dict_raw.get('Teraz czytam', np.nan)\n",
    "            }\n",
    "            \n",
    "            # Extract tags\n",
    "            tags = '&'.join([element.text.strip() for element in soup_book.find_all('a', class_='tag')])\n",
    "            \n",
    "            # Extract ratings\n",
    "            ratings_dict = {\n",
    "                f'rating_{element[\"data-rating\"]}': int(\"\".join(re.findall(NUMBER_PATTERN, element.text.strip())))\n",
    "                for element in soup_book.find_all('a', class_='chart-valuebtn btn-link--without-bold plusCountModal')\n",
    "            }\n",
    "            \n",
    "            # Combine all extracted data into a single dictionary\n",
    "            books_data_dict = {\n",
    "                **authors,\n",
    "                'description': description,\n",
    "                'number_of_user_opinions': number_of_user_opinions,\n",
    "                'number_of_user_ratings': number_of_user_ratings,\n",
    "                'number_of_discussions': number_of_discussions,\n",
    "                **details_dict,\n",
    "                **on_the_shelf_dict,\n",
    "                'tags': tags,\n",
    "                **ratings_dict,\n",
    "                'url': book_url\n",
    "            }\n",
    "            \n",
    "            # Append the book data dictionary to the list\n",
    "            books_data_dict_list.append(books_data_dict)\n",
    "            \n",
    "            # Sleep for a random time between requests to avoid being blocked\n",
    "            random_sleep_time = random.uniform(0.5, 1.5)\n",
    "            time.sleep(random_sleep_time)\n",
    "        # print current step of the loop and the only current step of the loop\n",
    "        print(f'Current step: {step}', end='\\r')\n",
    "except Exception as e:\n",
    "    print(f'Error: {e}')\n",
    "    # print traceback\n",
    "    import traceback\n",
    "    print('something went wrong')\n",
    "    traceback.print_exc()\n",
    "    # save data frames as tmp data frames to be merged later\n",
    "    books_df_tmp = pd.DataFrame(books_data_dict_list)\n",
    "    authors_df_tmp = pd.DataFrame(authors_data_dict_list)\n",
    "    books_df_tmp.to_csv('books_tmp.csv', index=False)\n",
    "    authors_df_tmp.to_csv('authors_tmp.csv', index=False)\n",
    "    print('tmp data frames saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'26656'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_soup.find_all('div', class_='author-box__readers-col')[0].find('span').text.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df = pd.DataFrame(books_data_dict_list)\n",
    "authors_df = pd.DataFrame(authors_data_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_df.to_csv('authors_tmp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df.to_csv('books_tmp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_href = books_df['author_href'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_href</th>\n",
       "      <th>description</th>\n",
       "      <th>number_of_user_opinions</th>\n",
       "      <th>number_of_user_ratings</th>\n",
       "      <th>number_of_discussions</th>\n",
       "      <th>Kategoria</th>\n",
       "      <th>Format</th>\n",
       "      <th>Wydawnictwo</th>\n",
       "      <th>Data wydania</th>\n",
       "      <th>...</th>\n",
       "      <th>author14</th>\n",
       "      <th>author_href14</th>\n",
       "      <th>author15</th>\n",
       "      <th>author_href15</th>\n",
       "      <th>author16</th>\n",
       "      <th>author_href16</th>\n",
       "      <th>author17</th>\n",
       "      <th>author_href17</th>\n",
       "      <th>author18</th>\n",
       "      <th>author_href18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>praca zbiorowa</td>\n",
       "      <td>https://lubimyczytac.pl/autor/8337/praca-zbiorowa</td>\n",
       "      <td>Biblia tzw. Brzeska (albo Pińczowska, albo Ra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>religia</td>\n",
       "      <td>papier</td>\n",
       "      <td>Arka, Cieszyńska Drukarnia Wydawnicza, Collegi...</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agata Romaniuk</td>\n",
       "      <td>https://lubimyczytac.pl/autor/71959/agata-roma...</td>\n",
       "      <td>O pierwszych miłościach powiedziano prawie ws...</td>\n",
       "      <td>396</td>\n",
       "      <td>2616</td>\n",
       "      <td>0</td>\n",
       "      <td>reportaż</td>\n",
       "      <td>papier</td>\n",
       "      <td>Wydawnictwo Poznańskie</td>\n",
       "      <td>2022-10-12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ewa Nowak</td>\n",
       "      <td>https://lubimyczytac.pl/autor/5021/ewa-nowak</td>\n",
       "      <td>Klasa maturalna, przystojniak Kuba Gwidosz je...</td>\n",
       "      <td>200</td>\n",
       "      <td>2502</td>\n",
       "      <td>0</td>\n",
       "      <td>literatura młodzieżowa</td>\n",
       "      <td>papier</td>\n",
       "      <td>Egmont Polska</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adam Mickiewicz</td>\n",
       "      <td>https://lubimyczytac.pl/autor/6520/adam-mickie...</td>\n",
       "      <td>W Dziadach. Część II Adam Mickiewicz sięga do...</td>\n",
       "      <td>155</td>\n",
       "      <td>2511</td>\n",
       "      <td>0</td>\n",
       "      <td>utwór dramatyczny (dramat, komedia, tragedia)</td>\n",
       "      <td>papier</td>\n",
       "      <td>IBIS</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Cabot</td>\n",
       "      <td>https://lubimyczytac.pl/autor/6222/meg-cabot</td>\n",
       "      <td>Do tańca proszą wampir, który zawrócił w głow...</td>\n",
       "      <td>234</td>\n",
       "      <td>2474</td>\n",
       "      <td>0</td>\n",
       "      <td>fantasy, science fiction</td>\n",
       "      <td>papier</td>\n",
       "      <td>Amber</td>\n",
       "      <td>2010-01-13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8138</th>\n",
       "      <td>Sally Page</td>\n",
       "      <td>https://lubimyczytac.pl/autor/230535/sally-page</td>\n",
       "      <td>...zauważyła, że ludzieopowiadają jej swoje h...</td>\n",
       "      <td>154</td>\n",
       "      <td>573</td>\n",
       "      <td>1</td>\n",
       "      <td>literatura obyczajowa, romans</td>\n",
       "      <td>papier</td>\n",
       "      <td>Insignis</td>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8139</th>\n",
       "      <td>Natalia Sońska</td>\n",
       "      <td>https://lubimyczytac.pl/autor/115156/natalia-s...</td>\n",
       "      <td>Gdybyś mogła mieć jedno życzenie, które na pe...</td>\n",
       "      <td>138</td>\n",
       "      <td>573</td>\n",
       "      <td>0</td>\n",
       "      <td>literatura obyczajowa, romans</td>\n",
       "      <td>papier</td>\n",
       "      <td>Czwarta Strona</td>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8140</th>\n",
       "      <td>Harry Harrison</td>\n",
       "      <td>https://lubimyczytac.pl/autor/20127/harry-harr...</td>\n",
       "      <td>Na skrajnie przeludnionej, zdegradowanej Ziem...</td>\n",
       "      <td>90</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>fantasy, science fiction</td>\n",
       "      <td>papier</td>\n",
       "      <td>Rebis</td>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8141</th>\n",
       "      <td>Anna Ciarkowska</td>\n",
       "      <td>https://lubimyczytac.pl/autor/153763/anna-ciar...</td>\n",
       "      <td>Przepraszam, czy mogę się u ciebie schować?Cz...</td>\n",
       "      <td>94</td>\n",
       "      <td>558</td>\n",
       "      <td>0</td>\n",
       "      <td>poezja</td>\n",
       "      <td>papier</td>\n",
       "      <td>Otwarte</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8142</th>\n",
       "      <td>Arnaldur Indriðason</td>\n",
       "      <td>https://lubimyczytac.pl/autor/31358/arnaldur-i...</td>\n",
       "      <td>To oczywiste samobójstwo. A jednak Komisarz E...</td>\n",
       "      <td>90</td>\n",
       "      <td>568</td>\n",
       "      <td>0</td>\n",
       "      <td>kryminał, sensacja, thriller</td>\n",
       "      <td>papier</td>\n",
       "      <td>W.A.B.</td>\n",
       "      <td>2016-08-17</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8143 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   author                                        author_href  \\\n",
       "0          praca zbiorowa  https://lubimyczytac.pl/autor/8337/praca-zbiorowa   \n",
       "1          Agata Romaniuk  https://lubimyczytac.pl/autor/71959/agata-roma...   \n",
       "2               Ewa Nowak       https://lubimyczytac.pl/autor/5021/ewa-nowak   \n",
       "3         Adam Mickiewicz  https://lubimyczytac.pl/autor/6520/adam-mickie...   \n",
       "4               Meg Cabot       https://lubimyczytac.pl/autor/6222/meg-cabot   \n",
       "...                   ...                                                ...   \n",
       "8138           Sally Page    https://lubimyczytac.pl/autor/230535/sally-page   \n",
       "8139       Natalia Sońska  https://lubimyczytac.pl/autor/115156/natalia-s...   \n",
       "8140       Harry Harrison  https://lubimyczytac.pl/autor/20127/harry-harr...   \n",
       "8141      Anna Ciarkowska  https://lubimyczytac.pl/autor/153763/anna-ciar...   \n",
       "8142  Arnaldur Indriðason  https://lubimyczytac.pl/autor/31358/arnaldur-i...   \n",
       "\n",
       "                                            description  \\\n",
       "0      Biblia tzw. Brzeska (albo Pińczowska, albo Ra...   \n",
       "1      O pierwszych miłościach powiedziano prawie ws...   \n",
       "2      Klasa maturalna, przystojniak Kuba Gwidosz je...   \n",
       "3      W Dziadach. Część II Adam Mickiewicz sięga do...   \n",
       "4      Do tańca proszą wampir, który zawrócił w głow...   \n",
       "...                                                 ...   \n",
       "8138   ...zauważyła, że ludzieopowiadają jej swoje h...   \n",
       "8139   Gdybyś mogła mieć jedno życzenie, które na pe...   \n",
       "8140   Na skrajnie przeludnionej, zdegradowanej Ziem...   \n",
       "8141   Przepraszam, czy mogę się u ciebie schować?Cz...   \n",
       "8142   To oczywiste samobójstwo. A jednak Komisarz E...   \n",
       "\n",
       "      number_of_user_opinions  number_of_user_ratings  number_of_discussions  \\\n",
       "0                           0                       0                      0   \n",
       "1                         396                    2616                      0   \n",
       "2                         200                    2502                      0   \n",
       "3                         155                    2511                      0   \n",
       "4                         234                    2474                      0   \n",
       "...                       ...                     ...                    ...   \n",
       "8138                      154                     573                      1   \n",
       "8139                      138                     573                      0   \n",
       "8140                       90                     546                      0   \n",
       "8141                       94                     558                      0   \n",
       "8142                       90                     568                      0   \n",
       "\n",
       "                                          Kategoria  Format  \\\n",
       "0                                           religia  papier   \n",
       "1                                          reportaż  papier   \n",
       "2                            literatura młodzieżowa  papier   \n",
       "3     utwór dramatyczny (dramat, komedia, tragedia)  papier   \n",
       "4                          fantasy, science fiction  papier   \n",
       "...                                             ...     ...   \n",
       "8138                  literatura obyczajowa, romans  papier   \n",
       "8139                  literatura obyczajowa, romans  papier   \n",
       "8140                       fantasy, science fiction  papier   \n",
       "8141                                         poezja  papier   \n",
       "8142                   kryminał, sensacja, thriller  papier   \n",
       "\n",
       "                                            Wydawnictwo Data wydania  ...  \\\n",
       "0     Arka, Cieszyńska Drukarnia Wydawnicza, Collegi...   2003-01-01  ...   \n",
       "1                                Wydawnictwo Poznańskie   2022-10-12  ...   \n",
       "2                                         Egmont Polska   2012-01-01  ...   \n",
       "3                                                  IBIS   2017-06-01  ...   \n",
       "4                                                 Amber   2010-01-13  ...   \n",
       "...                                                 ...          ...  ...   \n",
       "8138                                           Insignis   2022-09-28  ...   \n",
       "8139                                     Czwarta Strona   2020-10-28  ...   \n",
       "8140                                              Rebis   2019-09-17  ...   \n",
       "8141                                            Otwarte   2018-01-31  ...   \n",
       "8142                                             W.A.B.   2016-08-17  ...   \n",
       "\n",
       "     author14 author_href14 author15 author_href15 author16 author_href16  \\\n",
       "0         NaN           NaN      NaN           NaN      NaN           NaN   \n",
       "1         NaN           NaN      NaN           NaN      NaN           NaN   \n",
       "2         NaN           NaN      NaN           NaN      NaN           NaN   \n",
       "3         NaN           NaN      NaN           NaN      NaN           NaN   \n",
       "4         NaN           NaN      NaN           NaN      NaN           NaN   \n",
       "...       ...           ...      ...           ...      ...           ...   \n",
       "8138      NaN           NaN      NaN           NaN      NaN           NaN   \n",
       "8139      NaN           NaN      NaN           NaN      NaN           NaN   \n",
       "8140      NaN           NaN      NaN           NaN      NaN           NaN   \n",
       "8141      NaN           NaN      NaN           NaN      NaN           NaN   \n",
       "8142      NaN           NaN      NaN           NaN      NaN           NaN   \n",
       "\n",
       "     author17 author_href17 author18 author_href18  \n",
       "0         NaN           NaN      NaN           NaN  \n",
       "1         NaN           NaN      NaN           NaN  \n",
       "2         NaN           NaN      NaN           NaN  \n",
       "3         NaN           NaN      NaN           NaN  \n",
       "4         NaN           NaN      NaN           NaN  \n",
       "...       ...           ...      ...           ...  \n",
       "8138      NaN           NaN      NaN           NaN  \n",
       "8139      NaN           NaN      NaN           NaN  \n",
       "8140      NaN           NaN      NaN           NaN  \n",
       "8141      NaN           NaN      NaN           NaN  \n",
       "8142      NaN           NaN      NaN           NaN  \n",
       "\n",
       "[8143 rows x 76 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_133533/734529333.py:2: DtypeWarning: Columns (66,67,68,69,70,71,72,73,74,75) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_books_df = pd.read_csv(BOOKS_PATH)\n"
     ]
    }
   ],
   "source": [
    "if BOOKS_PATH.exists():\n",
    "    existing_books_df = pd.read_csv(BOOKS_PATH)\n",
    "else:\n",
    "    existing_books_df = pd.DataFrame()\n",
    "if AUTHORS_PATH.exists():\n",
    "    existing_authors_df = pd.read_csv(AUTHORS_PATH)\n",
    "else:\n",
    "    existing_authors_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Europe. A History'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lubimyczytac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
